{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "path = \"Downloads/default of credit card clients.xls\"\n",
    "df = pd.read_excel(path)\n",
    "df = df.dropna()\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"default payment next month\"]\n",
    "x = df.loc[:, df.columns != 'default payment next month']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=101)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Random Forest Classifier - Base Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics as skm\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=101)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "train_pred = rfc.predict(X_train)\n",
    "test_pred = rfc.predict(X_test)\n",
    "\n",
    "train_proba = rfc.predict_proba(X_train)\n",
    "test_proba = rfc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score is: 0.9793333333333333\n",
      "\n",
      "Train Confusion Matrix\n",
      "[[16284    22]\n",
      " [  412  4282]]\n",
      "\n",
      "Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     16306\n",
      "           1       0.99      0.91      0.95      4694\n",
      "\n",
      "    accuracy                           0.98     21000\n",
      "   macro avg       0.99      0.96      0.97     21000\n",
      "weighted avg       0.98      0.98      0.98     21000\n",
      "\n",
      "\n",
      "Train ROC AUC\n",
      "0.999152133637619\n"
     ]
    }
   ],
   "source": [
    "print(\"\\Train Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_train, train_pred))\n",
    "print(\"\\nTrain Classification Report\")\n",
    "print(skm.classification_report(y_train, train_pred))\n",
    "print(\"\\nTrain ROC AUC\")\n",
    "print(skm.roc_auc_score(y_train, train_proba[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.8056666666666666\n",
      "\n",
      "Test Confusion Matrix\n",
      "[[6637  421]\n",
      " [1328  614]]\n",
      "\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      7058\n",
      "           1       0.59      0.32      0.41      1942\n",
      "\n",
      "    accuracy                           0.81      9000\n",
      "   macro avg       0.71      0.63      0.65      9000\n",
      "weighted avg       0.78      0.81      0.78      9000\n",
      "\n",
      "\n",
      "Test ROC AUC\n",
      "0.7289395807986729\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_test, test_pred))\n",
    "print(\"\\nTest Classification Report\")\n",
    "print(skm.classification_report(y_test, test_pred))\n",
    "print(\"\\nTest ROC AUC\")\n",
    "print(skm.roc_auc_score(y_test, test_proba[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Calculate predictions for the training data & build the classification report & roc_auc_score. Are there signs of overfitting? Why or why not?\n",
    "\n",
    "Answer: There are signs of overfitting. First, the training ROC AUC score for trainning is extremely high (0.999), which is an sign of extreme overfitting. Further, the trianing precision, recall, accuracy and ROC AUC scores are very high (all in the high 90s%) while the testing precision, recall accuracy and ROC AUC scores are significantly lower (mostly around 70%), which is an indication that the model fits very well with the training data but not so well with the testing data (overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Random Forest Classifier - Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [6, 8, 10, 12], 'max_features': [2, 4, 6],\n",
       "                         'n_estimators': [50, 100, 500],\n",
       "                         'random_state': [101]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#create a dictionary of parameters \n",
    "param_grid = {'max_depth':[6, 8, 10, 12],\n",
    "'n_estimators':[50, 100, 500],\n",
    "'max_features':[2, 4, 6],\n",
    "'random_state':[101]}\n",
    "\n",
    "# create Random Forest model \n",
    "rf_obj=RandomForestClassifier()\n",
    "\n",
    "# Create gridsearch object with various combinations of parameters\n",
    "rf_Grid = GridSearchCV(rf_obj, param_grid, cv = 5, scoring = 'roc_auc',refit = True, n_jobs=-1, verbose = 5)\n",
    "\n",
    "rf_Grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 12, 'max_features': 2, 'n_estimators': 500, 'random_state': 101}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=12, max_features=2, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=101,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = rf_Grid.best_estimator_\n",
    "\n",
    "train_predict = rf.predict(X_train)\n",
    "test_predict = rf.predict(X_test)\n",
    "\n",
    "train_probab = rf.predict_proba(X_train)\n",
    "test_probab = rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix\n",
      "[[16106   200]\n",
      " [ 2483  2211]]\n",
      "\n",
      "Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92     16306\n",
      "           1       0.92      0.47      0.62      4694\n",
      "\n",
      "    accuracy                           0.87     21000\n",
      "   macro avg       0.89      0.73      0.77     21000\n",
      "weighted avg       0.88      0.87      0.86     21000\n",
      "\n",
      "\n",
      "Train ROC AUC: 0.9082534935423091\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_train, train_predict))\n",
    "print(\"\\nTrain Classification Report\")\n",
    "print(skm.classification_report(y_train, train_predict))\n",
    "print(\"\\nTrain ROC AUC:\", skm.roc_auc_score(y_train, train_probab[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Confusion Matrix\n",
      "[[6768  290]\n",
      " [1349  593]]\n",
      "\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      7058\n",
      "           1       0.67      0.31      0.42      1942\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.75      0.63      0.66      9000\n",
      "weighted avg       0.80      0.82      0.79      9000\n",
      "\n",
      "\n",
      "Test ROC AUC: 0.7772604817111946\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_test, test_predict))\n",
    "print(\"\\nTest Classification Report\")\n",
    "print(skm.classification_report(y_test, test_predict))\n",
    "print(\"\\nTest ROC AUC:\", skm.roc_auc_score(y_test, test_probab[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Calculate predictions for the training data & build the confusion matrix, classification report & roc_auc_score. Are there signs of overfitting? Why or why not?\n",
    "\n",
    "Answer: There are signs of overfitting. The trianing precision, recall, accuracy and ROC AUC scores are very high (all around 90%) while the testing precision, recall accuracy and ROC AUC scores are relatively lower (mostly around 80%), which might an indication that the model fits  well with the training data but not as well with the testing data (overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a feature importance plot for your best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a28b9f8d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi = pd.DataFrame({'features': X_train.columns, 'importance': rf.feature_importances_})\n",
    "fi.sort_values('importance', ascending=False, inplace=True)\n",
    "fi.plot.bar(x='features', y='importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What are the top 5 features for this model?\n",
    "\n",
    "Answer: The top 5 features for this model are PAY_0, PAY_2, PAY_3, PAY_4 and PAY_AMT1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Conceptual Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What are the best parameters from the Grid Search in Question # 3? Does the Model from # 3 outperform Model # 2? Explain why.\n",
    "\n",
    "Answer: The best parameters from the Grid Search in model 3 are max_depth = 12, max_features = 2, and n_estimators = 500. For training data, model 2 has higher precision, recall, accuray, and ROC AUC scores while for testing data, model 3 has higher precision, recall, accuracy and ROC AUC scores. However, the high training scores and low testing scores in model 2 seems to indicate that model 2 is overfitting the data. Therefore, we conclude model 3 outperform model 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Overfitting is always a concern in ML problems. Does Model # 3 overfit data more or less than Model # 2? Explain why you think this is the case.\n",
    "\n",
    "Answer: Even though both model 2 and model 3 have signs of overfitting, model 2's training scores are extremely high (more likely to indicate overfitting) and the difference between training and testing scores for model 2 is bigger than the difference between training and testing scores for model 3. Therefore, model 3 overfits data less than model 2. One of the reasons why model 2 overfits data less than model 2 is because we use 5 cross fold validation in model 2, using cross validation can help find the optimal parameters and mitigate overfiting (please refer to question f as to how cross validation works). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) The lecture notes describe the Gini Index which is the default criterion used for splitting in sklearn's version of RandomForestClassifier. How does the Gini Index work? (i.e. How is it used to build a top-performing model?).\n",
    "\n",
    "Answer: We use the Gini index to measure the impurity of each node. The lower the Gini index in a specific node, the fewer classes that the samples in the nodes belongs to, which indicates the classification tree has done a good job in separating each class. The Gini index is calculated by one minus the sum of the squared ratios of class k instance in a specific node. For instance, if at one node, there are total of 50 samples with k possible classes, then the Gini index is one minus the sum of the squared ratios of this 50 samples being classified into k different classes. If all the samples in this node only belongs to class k, then the sum of these ratios should be 1 (squared(50/50) for class k and squared(0/50) for all other classes), and the Gini index should be 0, which is means the splits leading to this node has done a very good job in classifying class k samples as the samples in this node only belongs to one class. Using the Gini index to evaluate the performance of each split by calculating the purity of all its resulting nodes, and it can help us measure the performance of our tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Describe how Random Forest is different from bagging & why this difference can yield improved results.\n",
    "\n",
    "Answer: The main difference between random forest and bagging trees is that Random forests only takes a subset of features at random and split a node based on that subset of features. For bagging tress, all the features are considered when determining the split of a node. For bagging trees, since it takes all the features to split a tree, not only the trees depend heavily on the training sample, but they are also highly correlated in the prediction. On the other hand, since random forest only takes a subset of features to determine the split, the trees are more independent of each other as compared to bagging trees, and by reducing correlation between trees, random forest helps reduce variances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Describe the importance of the max_depth parameter in Random Forest. Do not just provide a definition, rather think through how bias-variance tradeoff might be impacted by the max_depth parameter.\n",
    "\n",
    "Answer: The max_depth parameter in random forest represents the depth of each tree in the forest. The deeper the tree, the more splits it has, and the more information the tree captured. However, having more splits might cause overfit because it captures too many information about the training dataset that might not be relevant to the testing data. Therefore, setting the max depth of the trees can avoid overfit. The deeper the trees grow, the more variance in the model since it captures more information than needed from the training data. On the other hand, severely limiting the depth of the trees can lead to increase of bias since it might not be able to capture all the useful information in the training data before hitting the limit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) In this homework we used k-fold cross-validation while determining the optimal hyperparameters for our Random Forest model. 1) Describe how k-fold cross-validation works. 2) What benefit do we gain by using k-fold cross-validation when tuning our Random Forest model versus only using the train-test split approach?\n",
    "\n",
    "Answer: \n",
    "a) K-fold cross-validation is when a dataset is split into k number of subsets where each subset is used as a testing set at some point. For instance, in model 3 in this homework, we used 5-Fold cross validation in our random forest model, which our dataset is split into 5 subsets. In the first iteration, the first subset is used as our testing set and the rest of the 4 subset are used to train the model. In the second iteration, the second subset is used as the testing set and the rest are used as the training set. This process is repeated until each of the 5 subsets have been used as the testing set.\n",
    "\n",
    "b) The benefit of using k-fold cross-validation when tuning our random forest model is that all of our data will be used in the training and testing set at some point during the process, which can avoid fitting and testing the data only by a random subset of our data. Since in random forest, the splits of the tree depend heavily on the training set, if the randomly selected training set is not a good representative of the whole dataset, the trained tree might be bias toward the training data, which then lead to bad performance in testing. On the other hand, using k-fold cross-validation can avoid this problem since the parameters are tuned and the results are validated during the process when each subset of the data is used as training and testing set. Thus, the final trained model would be more generalized and representative for the entire dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
