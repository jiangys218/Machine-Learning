{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Processing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D, Embedding, Reshape, Concatenate, Dropout\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from keras.models import model_from_yaml\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a)\n",
    "train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'Downloads/dataset_train', \n",
    "        target_size = (64, 64),  \n",
    "        batch_size = 32,\n",
    "        class_mode = 'categorical') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Take a look at your training set: \n",
    "1. What is the image shape of each training observation?\n",
    "\n",
    "Answer: The original image shape is (800,800,3) (see code below). The traget image size is (64,64,3) as we specify the target size in the train generator above. \n",
    "\n",
    "2. How many total classes do we need to predict on? \n",
    "\n",
    "Answer: There are total of 4 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 800, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img = load_img('Downloads/dataset_train/category 1/1010.png')\n",
    "x = img_to_array(img)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Initial Classifier Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64,64,3), activation = \"relu\"))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Conv2D(64, (3, 3), activation= 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units = 128, activation='relu'))\n",
    "classifier.add(Dense(units = 4, activation='softmax'))\n",
    "classifier.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. steps_per_epoch: 10, epochs: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 5s 454ms/step - loss: 1.0350 - accuracy: 0.6858\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 0.2008 - accuracy: 0.9444\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 0.1153 - accuracy: 0.9662\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 5s 466ms/step - loss: 0.0612 - accuracy: 0.9797\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 4s 422ms/step - loss: 0.0358 - accuracy: 0.9861\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 4s 450ms/step - loss: 0.0202 - accuracy: 0.9932\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 4s 431ms/step - loss: 0.0217 - accuracy: 0.9896\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 4s 448ms/step - loss: 0.0098 - accuracy: 0.9966\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 4s 402ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 4s 401ms/step - loss: 0.0064 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x145168c50>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "classifier.fit_generator(train_generator,steps_per_epoch=10,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "# write model and model weights to disk\n",
    "model_yaml = classifier.to_yaml()\n",
    "with open(\"model_1.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "classifier.save_weights(\"model_1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([1])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c)\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from keras.models import model_from_yaml\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "\n",
    "# load model from disk\n",
    "yaml_file = open('Desktop/model_1.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "model = tf.keras.models.model_from_yaml(loaded_model_yaml)\n",
    "\n",
    "# load weights into new model\n",
    "model.load_weights(\"model_1.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# test data path\n",
    "img_dir = \"Downloads/dataset_test\" # Enter Directory of all images\n",
    "\n",
    "# iterate over each test image\n",
    "# make a prediction and add to results \n",
    "data_path = os.path.join(img_dir, '*g')\n",
    "files = glob.glob(data_path)\n",
    "data = []\n",
    "results = []\n",
    "for f1 in files:\n",
    "    img = image.load_img(f1, target_size = (64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    data.append(img)\n",
    "    result = model.predict(img)\n",
    "    r = np.argmax(result, axis=1)\n",
    "    results.append(r)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Downloads/dataset_test/C033.png',\n",
       " 'Downloads/dataset_test/1022.png',\n",
       " 'Downloads/dataset_test/4011.png',\n",
       " 'Downloads/dataset_test/1053.png',\n",
       " 'Downloads/dataset_test/6051.png',\n",
       " 'Downloads/dataset_test/4053.png',\n",
       " 'Downloads/dataset_test/C014.png',\n",
       " 'Downloads/dataset_test/6023.png']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set class indices: {'category 1': 0, 'category 2': 1, 'category 3': 2, 'category 4': 3}\n",
      "classification result [3, 0, 1, 0, 1, 2, 1, 1]\n",
      "accuracy rate for model 1: 0.5\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "print(\"train set class indices:\",train_generator.class_indices)\n",
    "\n",
    "correct_class = np.array([3,0,1,0,2,1,3,2])\n",
    "import itertools\n",
    "result1 = list(itertools.chain.from_iterable(results))\n",
    "accuracy_rate1 = sum(correct_class == result1)/len(correct_class)\n",
    "print(\"classification result\", result1)\n",
    "print(\"accuracy rate for model 1:\", accuracy_rate1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. steps_per_epoch: 10, epochs: 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 4s 418ms/step - loss: 0.0068 - accuracy: 0.9965\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 0.0159 - accuracy: 0.9899\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 5s 504ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 5s 516ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 5s 455ms/step - loss: 8.8414e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 4s 403ms/step - loss: 0.0066 - accuracy: 0.9966\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 4s 401ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 4s 408ms/step - loss: 0.0132 - accuracy: 0.9932\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.0071 - accuracy: 0.9966\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 4s 405ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 5s 454ms/step - loss: 7.6129e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 7s 701ms/step - loss: 1.9869e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 6s 593ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 4s 435ms/step - loss: 7.9303e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 5s 458ms/step - loss: 2.0295e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 5s 536ms/step - loss: 4.0961e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 5s 458ms/step - loss: 4.0950e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 4s 415ms/step - loss: 3.3886e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 2.0003e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_2 = classifier.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=10,\n",
    "            epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and weights\n",
    "with open(\"model_2.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "classifier.save_weights(\"model_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and weights\n",
    "yaml_file2 = open('model_2.yaml', 'r')\n",
    "loaded_model_yaml2 = yaml_file2.read()\n",
    "yaml_file2.close()\n",
    "model2 = tf.keras.models.model_from_yaml(loaded_model_yaml2)\n",
    "\n",
    "model2.load_weights(\"model_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct classification [3 0 1 0 2 1 3 2]\n",
      "classification result [3, 0, 1, 0, 1, 2, 1, 1]\n",
      "accuracy rate for model 2: 0.5\n"
     ]
    }
   ],
   "source": [
    "# iterate over each test image\n",
    "# make a prediction and add to results \n",
    "data = []\n",
    "results2 = []\n",
    "for f1 in files:\n",
    "    img = image.load_img(f1, target_size = (64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    data.append(img)\n",
    "    result2 = model2.predict(img)\n",
    "    r2 = np.argmax(result2, axis=1)\n",
    "    results2.append(r2)\n",
    "\n",
    "\n",
    "result2 = list(itertools.chain.from_iterable(results2))\n",
    "accuracy_rate2 = sum(correct_class == result2)/len(correct_class)\n",
    "print(\"correct classification\", correct_class)\n",
    "print(\"classification result\", result2)\n",
    "print(\"accuracy rate for model 2:\", accuracy_rate2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-3. steps_per_epoch: 10, epochs: 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - 5s 539ms/step - loss: 1.9436e-04 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 4s 431ms/step - loss: 9.7374e-05 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 4s 429ms/step - loss: 1.6439e-04 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 4s 420ms/step - loss: 2.5241e-04 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 4s 421ms/step - loss: 8.5637e-05 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 1.1694e-04 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 5s 471ms/step - loss: 9.1273e-05 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 9.0882e-05 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 4s 442ms/step - loss: 4.2279e-05 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 4s 422ms/step - loss: 2.1371e-04 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 4s 416ms/step - loss: 1.1394e-04 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 4s 420ms/step - loss: 5.5647e-05 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 5s 505ms/step - loss: 1.6148e-04 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 5.2712e-05 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 5s 526ms/step - loss: 5.8059e-05 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 5s 473ms/step - loss: 8.9114e-05 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 5s 480ms/step - loss: 3.4580e-05 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 5s 463ms/step - loss: 1.1342e-04 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 4s 410ms/step - loss: 8.8827e-05 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 4s 418ms/step - loss: 8.5725e-05 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 4s 439ms/step - loss: 3.1061e-05 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 3.8033e-05 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 4s 421ms/step - loss: 3.9113e-05 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 5s 471ms/step - loss: 2.7763e-05 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 5s 511ms/step - loss: 2.8976e-05 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 2.9288e-05 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 1.6286e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 5s 509ms/step - loss: 8.9080e-05 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 4s 405ms/step - loss: 2.2721e-05 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 7.2101e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_3 = classifier.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=10,\n",
    "            epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and weights\n",
    "with open(\"model_3.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "classifier.save_weights(\"model_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and weights\n",
    "yaml_file3 = open('model_3.yaml', 'r')\n",
    "loaded_model_yaml3 = yaml_file3.read()\n",
    "yaml_file3.close()\n",
    "model3 = tf.keras.models.model_from_yaml(loaded_model_yaml3)\n",
    "\n",
    "model3.load_weights(\"model_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct classification [3 0 1 0 2 1 3 2]\n",
      "classification result [3, 0, 1, 0, 1, 2, 1, 1]\n",
      "accuracy rate for model 3: 0.5\n"
     ]
    }
   ],
   "source": [
    "# iterate over each test image\n",
    "# make a prediction and add to results \n",
    "data = []\n",
    "results3 = []\n",
    "for f1 in files:\n",
    "    img = image.load_img(f1, target_size = (64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    data.append(img)\n",
    "    result3 = model3.predict(img)\n",
    "    r3 = np.argmax(result3, axis=1)\n",
    "    results3.append(r3)\n",
    "\n",
    "\n",
    "result3 = list(itertools.chain.from_iterable(results3))\n",
    "accuracy_rate3 = sum(correct_class == result3)/len(correct_class)\n",
    "print(\"correct classification\", correct_class)\n",
    "print(\"classification result\", result3)\n",
    "print(\"accuracy rate for model 3:\", accuracy_rate3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-4. steps_per_epoch: 30, epochs: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 13s 444ms/step - loss: 5.2155e-05 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 13s 435ms/step - loss: 3.1566e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 14s 469ms/step - loss: 3.4368e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 14s 457ms/step - loss: 5.5155e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 13s 439ms/step - loss: 3.1630e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 13s 444ms/step - loss: 1.8791e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 13s 437ms/step - loss: 3.3689e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 15s 512ms/step - loss: 2.5881e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 14s 473ms/step - loss: 1.8813e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 13s 429ms/step - loss: 2.1634e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_4 = classifier.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=30,\n",
    "            epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and weights\n",
    "with open(\"model_4.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "classifier.save_weights(\"model_4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and weights\n",
    "yaml_file4 = open('model_4.yaml', 'r')\n",
    "loaded_model_yaml4 = yaml_file4.read()\n",
    "yaml_file4.close()\n",
    "model4 = tf.keras.models.model_from_yaml(loaded_model_yaml4)\n",
    "\n",
    "model4.load_weights(\"model_4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct classification [3 0 1 0 2 1 3 2]\n",
      "classification result [3, 0, 1, 0, 1, 2, 1, 1]\n",
      "accuracy rate for model 4: 0.5\n"
     ]
    }
   ],
   "source": [
    "# iterate over each test image\n",
    "# make a prediction and add to results \n",
    "data = []\n",
    "results4 = []\n",
    "for f1 in files:\n",
    "    img = image.load_img(f1, target_size = (64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    data.append(img)\n",
    "    result4 = model4.predict(img)\n",
    "    r4 = np.argmax(result4, axis=1)\n",
    "    results4.append(r4)\n",
    "\n",
    "\n",
    "result4 = list(itertools.chain.from_iterable(results4))\n",
    "accuracy_rate4 = sum(correct_class == result4)/len(correct_class)\n",
    "print(\"correct classification\", correct_class)\n",
    "print(\"classification result\", result4)\n",
    "print(\"accuracy rate for model 4:\", accuracy_rate4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5. steps_per_epoch: 30, epochs: 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 13s 426ms/step - loss: 2.6872e-05 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 12s 411ms/step - loss: 1.9473e-05 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 12s 404ms/step - loss: 2.4010e-05 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 12s 407ms/step - loss: 1.9326e-05 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 12s 408ms/step - loss: 1.6813e-05 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 12s 409ms/step - loss: 1.4616e-05 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 12s 408ms/step - loss: 9.8720e-06 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 12s 410ms/step - loss: 1.0139e-05 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 12s 406ms/step - loss: 1.4866e-05 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 12s 404ms/step - loss: 5.1545e-05 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 12s 404ms/step - loss: 8.9801e-06 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 12s 408ms/step - loss: 8.6645e-06 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 12s 411ms/step - loss: 2.1536e-05 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 12s 416ms/step - loss: 9.3006e-06 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 12s 409ms/step - loss: 1.3151e-05 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 12s 412ms/step - loss: 1.3411e-05 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 12s 401ms/step - loss: 1.5459e-05 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 12s 399ms/step - loss: 1.2652e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 12s 405ms/step - loss: 9.5226e-06 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 12s 403ms/step - loss: 7.7391e-06 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_5 = classifier.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=30,\n",
    "            epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and weights\n",
    "with open(\"model_5.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "classifier.save_weights(\"model_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and weights\n",
    "yaml_file5 = open('model_5.yaml', 'r')\n",
    "loaded_model_yaml5 = yaml_file5.read()\n",
    "yaml_file5.close()\n",
    "model5 = tf.keras.models.model_from_yaml(loaded_model_yaml5)\n",
    "\n",
    "model5.load_weights(\"model_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct classification [3 0 1 0 2 1 3 2]\n",
      "classification result [3, 0, 1, 0, 1, 2, 1, 1]\n",
      "accuracy rate for model 5: 0.5\n"
     ]
    }
   ],
   "source": [
    "# iterate over each test image\n",
    "# make a prediction and add to results \n",
    "data = []\n",
    "results5 = []\n",
    "for f1 in files:\n",
    "    img = image.load_img(f1, target_size = (64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    data.append(img)\n",
    "    result5 = model5.predict(img)\n",
    "    r5 = np.argmax(result5, axis=1)\n",
    "    results5.append(r5)\n",
    "\n",
    "\n",
    "result5 = list(itertools.chain.from_iterable(results5))\n",
    "accuracy_rate5 = sum(correct_class == result5)/len(correct_class)\n",
    "print(\"correct classification\", correct_class)\n",
    "print(\"classification result\", result5)\n",
    "print(\"accuracy rate for model 5:\", accuracy_rate5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-6. steps_per_epoch: 30, epochs: 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "30/30 [==============================] - 13s 428ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "30/30 [==============================] - 12s 408ms/step - loss: 8.3944e-04 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "30/30 [==============================] - 12s 413ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "30/30 [==============================] - 12s 411ms/step - loss: 3.9628e-04 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "30/30 [==============================] - 12s 402ms/step - loss: 1.9551e-04 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "30/30 [==============================] - 12s 405ms/step - loss: 3.7084e-04 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "30/30 [==============================] - 13s 445ms/step - loss: 8.4064e-04 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "30/30 [==============================] - 12s 406ms/step - loss: 3.5090e-04 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "30/30 [==============================] - 12s 408ms/step - loss: 8.4436e-05 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "30/30 [==============================] - 12s 409ms/step - loss: 9.7123e-05 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "30/30 [==============================] - 12s 404ms/step - loss: 7.3802e-05 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "30/30 [==============================] - 12s 407ms/step - loss: 9.9564e-05 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "30/30 [==============================] - 12s 406ms/step - loss: 6.1459e-05 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "30/30 [==============================] - 12s 408ms/step - loss: 5.3613e-05 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "30/30 [==============================] - 12s 407ms/step - loss: 5.2471e-05 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "30/30 [==============================] - 12s 404ms/step - loss: 5.0770e-05 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "30/30 [==============================] - 12s 408ms/step - loss: 3.4669e-05 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "30/30 [==============================] - 12s 405ms/step - loss: 3.3769e-05 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "30/30 [==============================] - 12s 404ms/step - loss: 3.1941e-05 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "30/30 [==============================] - 12s 403ms/step - loss: 3.4815e-05 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "30/30 [==============================] - 12s 416ms/step - loss: 2.0596e-05 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "30/30 [==============================] - 13s 446ms/step - loss: 3.0635e-05 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "30/30 [==============================] - 14s 481ms/step - loss: 1.8367e-05 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "30/30 [==============================] - 13s 440ms/step - loss: 1.6825e-05 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "30/30 [==============================] - 12s 406ms/step - loss: 1.6248e-05 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "30/30 [==============================] - 12s 416ms/step - loss: 9.8934e-06 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "30/30 [==============================] - 12s 405ms/step - loss: 1.6751e-05 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "30/30 [==============================] - 12s 404ms/step - loss: 1.4337e-05 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "30/30 [==============================] - 12s 407ms/step - loss: 1.1519e-05 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "30/30 [==============================] - 12s 408ms/step - loss: 1.1505e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_6 = classifier.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=30,\n",
    "            epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and weights\n",
    "with open(\"model_6.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "classifier.save_weights(\"model_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and weights\n",
    "yaml_file6 = open('model_6.yaml', 'r')\n",
    "loaded_model_yaml6 = yaml_file6.read()\n",
    "yaml_file6.close()\n",
    "model6 = tf.keras.models.model_from_yaml(loaded_model_yaml6)\n",
    "\n",
    "model6.load_weights(\"model_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct classification [3 0 1 0 2 1 3 2]\n",
      "classification result [3, 0, 2, 0, 1, 2, 1, 1]\n",
      "accuracy rate for model 6: 0.375\n"
     ]
    }
   ],
   "source": [
    "# iterate over each test image\n",
    "# make a prediction and add to results \n",
    "data = []\n",
    "results6 = []\n",
    "for f1 in files:\n",
    "    img = image.load_img(f1, target_size = (64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    data.append(img)\n",
    "    result6 = model6.predict(img)\n",
    "    r6 = np.argmax(result6, axis=1)\n",
    "    results6.append(r6)\n",
    "\n",
    "\n",
    "result6 = list(itertools.chain.from_iterable(results6))\n",
    "accuracy_rate6 = sum(correct_class == result6)/len(correct_class)\n",
    "print(\"correct classification\", correct_class)\n",
    "print(\"classification result\", result6)\n",
    "print(\"accuracy rate for model 6:\", accuracy_rate6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-7. steps_per_epoch: 50, epochs: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 22s 450ms/step - loss: 7.8863e-06 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 21s 426ms/step - loss: 2.2137e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 21s 426ms/step - loss: 1.0147e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 23s 455ms/step - loss: 7.1070e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 23s 459ms/step - loss: 5.4745e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 22s 432ms/step - loss: 9.8681e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 21s 429ms/step - loss: 4.8397e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 7.0895e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 23s 463ms/step - loss: 3.6661e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 21s 421ms/step - loss: 2.2027e-06 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_7 = classifier.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=50,\n",
    "            epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and weights\n",
    "with open(\"model_7.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "classifier.save_weights(\"model_7.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and weights\n",
    "yaml_file7 = open('model_7.yaml', 'r')\n",
    "loaded_model_yaml7 = yaml_file7.read()\n",
    "yaml_file7.close()\n",
    "model7 = tf.keras.models.model_from_yaml(loaded_model_yaml7)\n",
    "\n",
    "model7.load_weights(\"model_7.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct classification [3 0 1 0 2 1 3 2]\n",
      "classification result [3, 0, 2, 0, 1, 2, 1, 1]\n",
      "accuracy rate for model 7: 0.375\n"
     ]
    }
   ],
   "source": [
    "# iterate over each test image\n",
    "# make a prediction and add to results \n",
    "data = []\n",
    "results7 = []\n",
    "for f1 in files:\n",
    "    img = image.load_img(f1, target_size = (64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    data.append(img)\n",
    "    result7 = model7.predict(img)\n",
    "    r7 = np.argmax(result7, axis=1)\n",
    "    results7.append(r7)\n",
    "\n",
    "\n",
    "result7 = list(itertools.chain.from_iterable(results7))\n",
    "accuracy_rate7 = sum(correct_class == result7)/len(correct_class)\n",
    "print(\"correct classification\", correct_class)\n",
    "print(\"classification result\", result7)\n",
    "print(\"accuracy rate for model 7:\", accuracy_rate7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-8. steps_per_epoch: 50, epochs: 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50/50 [==============================] - 21s 428ms/step - loss: 2.8892e-06 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 3.9141e-06 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 4.8645e-06 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 21s 422ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 21s 414ms/step - loss: 0.0339 - accuracy: 0.9870\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 5.6070e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 7.6062e-05 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 21s 420ms/step - loss: 4.9928e-05 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 25s 502ms/step - loss: 4.2128e-05 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 22s 443ms/step - loss: 1.2606e-05 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 1.5218e-05 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 21s 411ms/step - loss: 2.2946e-05 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 1.0189e-05 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 1.1754e-05 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 1.5415e-05 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 1.2173e-05 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 21s 414ms/step - loss: 1.1197e-05 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 8.3129e-06 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 3.8647e-06 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 4.7805e-06 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_8 = classifier.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=50,\n",
    "            epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and weights\n",
    "with open(\"model_8.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "classifier.save_weights(\"model_8.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and weights\n",
    "yaml_file8 = open('model_8.yaml', 'r')\n",
    "loaded_model_yaml8 = yaml_file8.read()\n",
    "yaml_file8.close()\n",
    "model8 = tf.keras.models.model_from_yaml(loaded_model_yaml8)\n",
    "\n",
    "model8.load_weights(\"model_8.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct classification [3 0 1 0 2 1 3 2]\n",
      "classification result [3, 0, 0, 0, 1, 2, 1, 1]\n",
      "accuracy rate for model 8: 0.375\n"
     ]
    }
   ],
   "source": [
    "# iterate over each test image\n",
    "# make a prediction and add to results \n",
    "data = []\n",
    "results8 = []\n",
    "for f1 in files:\n",
    "    img = image.load_img(f1, target_size = (64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    data.append(img)\n",
    "    result8 = model8.predict(img)\n",
    "    r8 = np.argmax(result8, axis=1)\n",
    "    results8.append(r8)\n",
    "\n",
    "\n",
    "result8 = list(itertools.chain.from_iterable(results8))\n",
    "accuracy_rate8 = sum(correct_class == result8)/len(correct_class)\n",
    "print(\"correct classification\", correct_class)\n",
    "print(\"classification result\", result8)\n",
    "print(\"accuracy rate for model 8:\", accuracy_rate8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-9.steps_per_epoch: 50, epochs: 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "50/50 [==============================] - 21s 417ms/step - loss: 3.8974e-06 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 21s 411ms/step - loss: 7.6562e-06 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 20s 407ms/step - loss: 2.8668e-06 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 20s 407ms/step - loss: 5.9319e-06 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 21s 417ms/step - loss: 1.2124e-05 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 21s 430ms/step - loss: 3.4099e-06 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 1.1730e-06 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 9.4762e-06 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 2.5445e-06 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 2.0320e-06 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 3.7615e-06 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 21s 428ms/step - loss: 1.6649e-06 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 22s 434ms/step - loss: 1.7743e-06 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 21s 416ms/step - loss: 2.5127e-06 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 21s 411ms/step - loss: 6.5657e-06 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 2.1484e-06 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 23s 454ms/step - loss: 2.4042e-06 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 20s 407ms/step - loss: 3.7635e-06 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 21s 413ms/step - loss: 1.0509e-06 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 1.8286e-06 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 20s 407ms/step - loss: 8.9951e-07 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 20s 410ms/step - loss: 7.2163e-07 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 20s 406ms/step - loss: 1.1706e-06 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 1.1095e-06 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 20s 407ms/step - loss: 1.1932e-06 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 21s 417ms/step - loss: 1.3495e-06 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 21s 427ms/step - loss: 8.1892e-07 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 23s 468ms/step - loss: 1.1571e-06 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 21s 419ms/step - loss: 1.1745e-06 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 22s 433ms/step - loss: 6.8478e-07 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_9 = classifier.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=50,\n",
    "            epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and weights\n",
    "with open(\"model_9.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "classifier.save_weights(\"model_9.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and weights\n",
    "yaml_file9 = open('model_9.yaml', 'r')\n",
    "loaded_model_yaml9 = yaml_file9.read()\n",
    "yaml_file9.close()\n",
    "model9 = tf.keras.models.model_from_yaml(loaded_model_yaml9)\n",
    "\n",
    "model9.load_weights(\"model_9.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct classification [3 0 1 0 2 1 3 2]\n",
      "classification result [3, 0, 0, 0, 1, 2, 1, 1]\n",
      "accuracy rate for model 9: 0.375\n"
     ]
    }
   ],
   "source": [
    "# iterate over each test image\n",
    "# make a prediction and add to results \n",
    "data = []\n",
    "results9 = []\n",
    "for f1 in files:\n",
    "    img = image.load_img(f1, target_size = (64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    data.append(img)\n",
    "    result9 = model9.predict(img)\n",
    "    r9 = np.argmax(result9, axis=1)\n",
    "    results9.append(r9)\n",
    "\n",
    "\n",
    "result9 = list(itertools.chain.from_iterable(results9))\n",
    "accuracy_rate9 = sum(correct_class == result9)/len(correct_class)\n",
    "print(\"correct classification\", correct_class)\n",
    "print(\"classification result\", result9)\n",
    "print(\"accuracy rate for model 9:\", accuracy_rate9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-10. steps_per_epoch: 50, epochs: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 21s 415ms/step - loss: 9.0275e-07 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 20s 406ms/step - loss: 6.0166e-07 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 21s 419ms/step - loss: 8.7161e-07 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 21s 426ms/step - loss: 8.8025e-07 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 5.5370e-07 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 21s 412ms/step - loss: 1.5155e-06 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 5.3538e-07 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 8.1390e-07 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 20s 401ms/step - loss: 5.5718e-07 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 20s 407ms/step - loss: 5.5358e-07 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 5.4129e-07 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 21s 425ms/step - loss: 3.5830e-07 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 5.6223e-07 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 1.8745e-06 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 21s 411ms/step - loss: 1.3486e-06 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 21s 410ms/step - loss: 7.1716e-07 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 4.2874e-06 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 2.4743e-07 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 8.7599e-07 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 20s 406ms/step - loss: 4.8498e-07 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 4.3031e-07 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 20s 407ms/step - loss: 4.2146e-07 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 20s 409ms/step - loss: 5.2437e-07 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 4.3846e-07 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 20s 406ms/step - loss: 2.7491e-07 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 20s 407ms/step - loss: 1.8782e-07 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 20s 409ms/step - loss: 6.6946e-07 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 20s 406ms/step - loss: 3.1747e-07 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 20s 409ms/step - loss: 1.0353e-06 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 2.3506e-07 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 3.9057e-07 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 1.0006e-06 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 20s 400ms/step - loss: 3.6596e-07 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 1.7144e-07 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 2.2240e-07 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 20s 406ms/step - loss: 2.5498e-07 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 2.9667e-07 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 2.3687e-07 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 2.4249e-07 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 2.0774e-07 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 2.0337e-07 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 1.8136e-07 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 21s 414ms/step - loss: 2.3558e-07 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 21s 424ms/step - loss: 1.0602e-07 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 1.3256e-07 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 1.5053e-07 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 20s 407ms/step - loss: 1.2371e-07 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 1.1026e-07 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 9.3653e-08 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 2.6321e-07 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 1.2710e-07 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 20s 406ms/step - loss: 1.9554e-07 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 7.9958e-08 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 20s 401ms/step - loss: 1.0770e-07 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 9.2447e-08 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 1.2390e-07 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 2.2638e-07 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 1.3446e-07 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 7.2953e-08 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 1.2401e-07 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 9.5466e-08 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 1.6186e-07 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 20s 401ms/step - loss: 1.5058e-07 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 20s 401ms/step - loss: 7.4861e-08 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 6.7262e-08 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 8.6233e-08 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 1.3192e-07 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 2.0215e-07 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 23s 450ms/step - loss: 8.2967e-08 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 21s 418ms/step - loss: 5.5323e-08 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 22s 431ms/step - loss: 1.5657e-07 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 22s 447ms/step - loss: 5.2594e-08 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 21s 417ms/step - loss: 1.2189e-07 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 9.7561e-08 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 21s 422ms/step - loss: 7.8383e-08 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 21s 425ms/step - loss: 2.7213e-07 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 20s 407ms/step - loss: 4.1189e-08 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 25s 506ms/step - loss: 1.0201e-07 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 21s 427ms/step - loss: 6.5553e-08 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 23s 450ms/step - loss: 1.4878e-07 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 3.9379e-08 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 21s 414ms/step - loss: 1.9895e-07 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 5.8574e-08 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 6.1395e-08 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 20s 409ms/step - loss: 4.5037e-08 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 20s 407ms/step - loss: 2.5832e-07 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 20s 407ms/step - loss: 4.7519e-08 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 21s 425ms/step - loss: 5.9439e-08 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 20s 407ms/step - loss: 3.4193e-08 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 20s 409ms/step - loss: 5.7141e-08 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 22s 439ms/step - loss: 6.1806e-08 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 20s 401ms/step - loss: 7.4638e-08 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 3.2379e-08 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 20s 409ms/step - loss: 7.0713e-08 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 20s 409ms/step - loss: 5.2362e-08 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 4.2512e-08 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 2.9448e-08 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 21s 416ms/step - loss: 3.1608e-08 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 1.8861e-08 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 20s 401ms/step - loss: 2.2271e-08 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_10 = classifier.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=50,\n",
    "            epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and weights\n",
    "with open(\"model_10.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "classifier.save_weights(\"model_10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and weights\n",
    "yaml_file10 = open('model_10.yaml', 'r')\n",
    "loaded_model_yaml10 = yaml_file10.read()\n",
    "yaml_file10.close()\n",
    "model10 = tf.keras.models.model_from_yaml(loaded_model_yaml10)\n",
    "\n",
    "model10.load_weights(\"model_10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct classification [3 0 1 0 2 1 3 2]\n",
      "classification result [3, 0, 0, 0, 1, 2, 1, 1]\n",
      "accuracy rate for model 10: 0.375\n"
     ]
    }
   ],
   "source": [
    "# iterate over each test image\n",
    "# make a prediction and add to results \n",
    "data = []\n",
    "results10 = []\n",
    "for f1 in files:\n",
    "    img = image.load_img(f1, target_size = (64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    data.append(img)\n",
    "    result10 = model10.predict(img)\n",
    "    r10 = np.argmax(result10, axis=1)\n",
    "    results10.append(r10)\n",
    "\n",
    "\n",
    "result10 = list(itertools.chain.from_iterable(results10))\n",
    "accuracy_rate10 = sum(correct_class == result10)/len(correct_class)\n",
    "print(\"correct classification\", correct_class)\n",
    "print(\"classification result\", result10)\n",
    "print(\"accuracy rate for model 10:\", accuracy_rate10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Steps per Epoch</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Steps per Epoch  Epochs  Accuracy\n",
       "0               10      10     0.500\n",
       "1               10      20     0.500\n",
       "2               10      30     0.500\n",
       "3               30      10     0.500\n",
       "4               30      20     0.500\n",
       "5               30      30     0.375\n",
       "6               50      10     0.375\n",
       "7               50      20     0.375\n",
       "8               50      30     0.375\n",
       "9               50     100     0.375"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f) \n",
    "import pandas as pd\n",
    "data = {'Steps per Epoch':[10,10,10,30,30,30,50,50,50,50], \n",
    "        'Epochs':[10,20,30,10,20,30,10,20,30,100], \n",
    "        'Accuracy':[accuracy_rate1, accuracy_rate2, accuracy_rate3, accuracy_rate4, \n",
    "                    accuracy_rate5, accuracy_rate6, accuracy_rate7, accuracy_rate8, \n",
    "                    accuracy_rate9, accuracy_rate10]} \n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceptual Questions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Discuss the effect of the following on accuracy and loss (train & test):\n",
    "\n",
    "a) Increasing the steps_per_epoch\n",
    "\n",
    "Answer: With increase in steps per epoch, the accuracy for train slightly increase (from close to 1 in previous models to all 1's in model 10). However, the testing accuracy is decreasing (from 0.5 in the earlier models to 0.375 in later models). Loss decreases as steps per epoch increases (from around e-02 in the earlier models to e-08 in the later models). \n",
    "\n",
    "b) Increasing the number of epochs\n",
    "\n",
    "Answer: The increase in number of epochs does not have a significant effect on training and testing accuracy as compared to the increase in steps per epoch. For training, the same epochs can have various of training accuracy, and there is no sign of how number of epochs had effect on training accuracy. Similary, for testing, epochs = 10, 20, 30 can have testing accuracy of 0.5 as well as 0.375). In addition, number of epochs does not have significant effect on the loss (loss decreases as steps per epoch increase, but it does not have any significant pattern with number of epochs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Name two uses of zero padding in CNN.\n",
    "\n",
    "Answer:\n",
    "\n",
    "Zero-padding is the process of symmetrically adding zeroes around the borders of the input matrix. It allows adjustment to the size of our input matrix the size. There are many uses of zero padding in CNN; the followings are just a few examples: \n",
    "\n",
    "a) Zero padding can be used when you want your output matrix to be the same size as your input matrix. For instance, if you have a input matrix of 4 * 4, and filter of 3 * 3, and output matrix should have a size of 2 * 2. If you use zero padding to your input matrix, the input matrix would have a size of 6 * 6, and with the same filter, your output matrix is also 4 * 4. \n",
    "\n",
    "b) Zero padding also help avoid loosing information at the boundaries. Without zero padding, the pixels at the borders are not trained as often as the pixels at the center, and hence, the border information might not be captured/ given weight as it should be.\n",
    "\n",
    "c) Zero padding can also be used when we want to train a deeper network. With zero padding, the iterations at the borders are only training on some of the pixels (and some zeros), which help the network train faster and enable a deeper network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What is the use of a 1 x 1 kernel in CNN?\n",
    "\n",
    "Answer: One of the use of a 1 x 1 kernel in CNN is for dimension reduction. For instance, if our input volumn is 63 * 64 * 192, and we apply a 1 * 1 kernel (in this case, it should be 1 * 1 * 192), then the output volumne should be 64 * 64 * 1. In this way, we reduce the depth while keeping the height and width of the feature map. This is reduce the computational needs, be more efficience and build deeper network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. What are the advantages of a CNN over a fully connected DNN for this image classification problem?\n",
    "\n",
    "Answer:\n",
    "\n",
    "The main advantage of CNN compared to a fully connected DNN is that it automatically detects the important features without any human supervision. For example, given many pictures of cats and dogs it learns distinctive features for each class by itself.\n",
    "\n",
    "Another main feature of CNNs is weight sharing, which help CNN to be more computationally efficent by computing less parameters. For instance, a one layered CNN with 5 filters of size 5x5, we have total of 5x5x5 +10 (bias) = 135 parameters to compute, which is way less when we consider if we have a fully connected DNN of a similar size. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
