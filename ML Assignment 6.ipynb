{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (507, 148)\n",
      "test shape (168, 148)\n"
     ]
    }
   ],
   "source": [
    "#a)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "trainpath = \"Downloads/train_data.csv\"\n",
    "testpath = \"Downloads/test_data.csv\"\n",
    "train = pd.read_csv(trainpath)\n",
    "test = pd.read_csv(testpath)\n",
    "print(\"train shape\", train.shape)\n",
    "print(\"test shape\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n",
    "train.replace([\"NaN\", 'NaT'], np.nan, inplace = True)\n",
    "train = train.dropna()\n",
    "test.replace([\"NaN\", 'NaT'], np.nan, inplace = True)\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c)\n",
    "y_train = train[\"class\"]\n",
    "X_train = train.loc[:, train.columns != 'class']\n",
    "y_test = test[\"class\"]\n",
    "X_test = test.loc[:, test.columns != 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d) \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest Classifier - Base Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a) \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n",
    "rf_test_pred = rf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Confusion Matrix\n",
      "[[14  0  0  0  0  0  0  0  0]\n",
      " [ 1 22  0  2  0  0  0  0  0]\n",
      " [ 0  2 13  0  0  0  0  0  0]\n",
      " [ 0  4  0 19  0  0  0  0  0]\n",
      " [ 0  0  0  0 25  0  0  0  4]\n",
      " [ 1  0  1  0  0 13  0  0  0]\n",
      " [ 3  0  0  0  0  0 13  0  0]\n",
      " [ 0  1  0  5  2  0  0  6  0]\n",
      " [ 0  0  0  1  1  0  0  0 15]]\n",
      "Testing Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.74      1.00      0.85        14\n",
      "   building        0.76      0.88      0.81        25\n",
      "        car        0.93      0.87      0.90        15\n",
      "   concrete        0.70      0.83      0.76        23\n",
      "      grass        0.89      0.86      0.88        29\n",
      "       pool        1.00      0.87      0.93        15\n",
      "     shadow        1.00      0.81      0.90        16\n",
      "       soil        1.00      0.43      0.60        14\n",
      "       tree        0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.83       168\n",
      "   macro avg       0.87      0.82      0.83       168\n",
      "weighted avg       0.86      0.83      0.83       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#c)\n",
    "from sklearn import metrics\n",
    "print(\"Testing Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_test, rf_test_pred))\n",
    "print(\"Testing Classification Report\")\n",
    "print(metrics.classification_report(y_test, rf_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix\n",
      "[[45  0  0  0  0  0  0  0  0]\n",
      " [ 0 97  0  0  0  0  0  0  0]\n",
      " [ 0  0 21  0  0  0  0  0  0]\n",
      " [ 0  0  0 93  0  0  0  0  0]\n",
      " [ 0  0  0  0 83  0  0  0  0]\n",
      " [ 0  0  0  0  0 14  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0]\n",
      " [ 0  0  0  0  0  0  0 20  0]\n",
      " [ 0  0  0  0  0  0  0  0 89]]\n",
      "Training Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        1.00      1.00      1.00        45\n",
      "   building        1.00      1.00      1.00        97\n",
      "        car        1.00      1.00      1.00        21\n",
      "   concrete        1.00      1.00      1.00        93\n",
      "      grass        1.00      1.00      1.00        83\n",
      "       pool        1.00      1.00      1.00        14\n",
      "     shadow        1.00      1.00      1.00        45\n",
      "       soil        1.00      1.00      1.00        20\n",
      "       tree        1.00      1.00      1.00        89\n",
      "\n",
      "    accuracy                           1.00       507\n",
      "   macro avg       1.00      1.00      1.00       507\n",
      "weighted avg       1.00      1.00      1.00       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "rf_train_pred = rf.predict(X_train_scaled)\n",
    "print(\"Training Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_train, rf_train_pred))\n",
    "print(\"Training Classification Report\")\n",
    "print(metrics.classification_report(y_train, rf_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Are there signs of overfitting? Why or why not?\n",
    "\n",
    "Answer: There are signs of overfitting. The training accuracy, precision, and recall scores are extremely high (all perfect 1.0), which is an sign of overfitting. In addition, the testing precision, recall accuracy and accuracy scores are relatively lower (except for class shadow and class soil), which is an indication that the model fits very well with the training data but not so well with the testing data (overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1ed1a7f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#e)\n",
    "fi_rf = pd.DataFrame({'features': X_train.columns, 'importance': rf.feature_importances_})\n",
    "fi_rf.sort_values('importance', ascending=False, inplace=True)\n",
    "fi_rf.iloc[:5,].plot.bar(x='features', y='importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LinearSVM Classifier - Base Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "from sklearn import svm\n",
    "svm = svm.LinearSVC()\n",
    "svm.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n",
    "svm_test_pred = svm.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Confusion Matrix\n",
      "[[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 22  1  1  1  0  0  0  0]\n",
      " [ 0  2 12  0  0  0  0  0  1]\n",
      " [ 1  6  0 15  0  0  0  0  1]\n",
      " [ 0  0  0  1 26  0  0  0  2]\n",
      " [ 1  0  1  0  0 13  0  0  0]\n",
      " [ 2  0  0  0  0  0 14  0  0]\n",
      " [ 0  4  0  1  3  0  0  6  0]\n",
      " [ 0  0  0  1  6  0  0  0 10]]\n",
      "Testing Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.76      0.93      0.84        14\n",
      "   building        0.65      0.88      0.75        25\n",
      "        car        0.86      0.80      0.83        15\n",
      "   concrete        0.79      0.65      0.71        23\n",
      "      grass        0.72      0.90      0.80        29\n",
      "       pool        1.00      0.87      0.93        15\n",
      "     shadow        0.93      0.88      0.90        16\n",
      "       soil        1.00      0.43      0.60        14\n",
      "       tree        0.71      0.59      0.65        17\n",
      "\n",
      "    accuracy                           0.78       168\n",
      "   macro avg       0.83      0.77      0.78       168\n",
      "weighted avg       0.80      0.78      0.77       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#c)\n",
    "from sklearn import metrics\n",
    "print(\"Testing Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_test, svm_test_pred))\n",
    "print(\"Testing Classification Report\")\n",
    "print(metrics.classification_report(y_test, svm_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix\n",
      "[[45  0  0  0  0  0  0  0  0]\n",
      " [ 0 97  0  0  0  0  0  0  0]\n",
      " [ 0  0 21  0  0  0  0  0  0]\n",
      " [ 0  0  0 93  0  0  0  0  0]\n",
      " [ 0  1  0  0 80  0  0  0  2]\n",
      " [ 0  0  0  0  0 14  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0]\n",
      " [ 0  0  0  0  0  0  0 20  0]\n",
      " [ 0  0  0  0  0  0  0  0 89]]\n",
      "Training Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        1.00      1.00      1.00        45\n",
      "   building        0.99      1.00      0.99        97\n",
      "        car        1.00      1.00      1.00        21\n",
      "   concrete        1.00      1.00      1.00        93\n",
      "      grass        1.00      0.96      0.98        83\n",
      "       pool        1.00      1.00      1.00        14\n",
      "     shadow        1.00      1.00      1.00        45\n",
      "       soil        1.00      1.00      1.00        20\n",
      "       tree        0.98      1.00      0.99        89\n",
      "\n",
      "    accuracy                           0.99       507\n",
      "   macro avg       1.00      1.00      1.00       507\n",
      "weighted avg       0.99      0.99      0.99       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "svm_train_pred = svm.predict(X_train_scaled)\n",
    "print(\"Training Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_train, svm_train_pred))\n",
    "print(\"Training Classification Report\")\n",
    "print(metrics.classification_report(y_train, svm_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Are there signs of overfitting? Why or why not?\n",
    "\n",
    "Answer:There are signs of overfitting. The training accuracy, precision, and recall scores are extremely high (all in high 90s% or perfect 100%), which is an sign of overfitting. In addition, the testing precision, recall accuracy and accuracy scores are relatively lower (except for class pool and class soil), which is an indication that the model fits very well with the training data but not so well with the testing data (overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Support Vector Machine Classifier + Linear Kernel + Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='linear', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': array([ 0.01,  0.2 ,  0.4 ,  0.6 ,  0.8 ,  1.  ,  1.2 ,  1.4 ,  1.6 ,\n",
       "        1.8 ,  2.  ,  2.2 ,  2.4 ,  2.6 ,  2.8 ,  3.  ,  3.2 ,  3.4 ,\n",
       "        3.6 ,  3.8 ,  4.  ,  4.2 ,  4.4 ,  4.6 ,  4.8 ,  5.  ,  5.2 ,\n",
       "        5.4 ,  5.6 ,  5.8 ,  6.  ,  6.2 ,  6.4 ,  6.6 ,  6.8 ,  7.  ,\n",
       "        7.2 ,  7.4 ,  7.6 ,  7.8 ,  8.  ,  8.2 ,  8.4 ,  8.6 ,  8.8 ,\n",
       "        9.  ,  9.2 ,  9.4 ,  9.6 ,  9.8 , 10.  ])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "para = np.arange(0.0, 10.2, 0.2)\n",
    "para[0] = 0.01\n",
    "parameters = {'C': para}\n",
    "svm = svm.SVC(kernel='linear')\n",
    "svm_linear = GridSearchCV(svm, parameters, cv=5, refit=True, n_jobs=-1, verbose=0, return_train_score=True)\n",
    "svm_linear.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Grid Search best parameters {'C': 0.01}\n",
      "SVM Grid Search best estimator SVC(C=0.01, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "print(\"SVM Grid Search best parameters\",svm_linear.best_params_)\n",
    "print(\"SVM Grid Search best estimator\",svm_linear.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c)\n",
    "svm_linear_gs = svm_linear.best_estimator_\n",
    "test_pred_svml = svm_linear_gs.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Confusion Matrix\n",
      "[[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 22  0  2  1  0  0  0  0]\n",
      " [ 0  1 14  0  0  0  0  0  0]\n",
      " [ 0  5  0 17  0  0  0  1  0]\n",
      " [ 0  0  0  1 25  0  0  0  3]\n",
      " [ 0  0  0  0  0 14  1  0  0]\n",
      " [ 1  0  0  0  0  0 15  0  0]\n",
      " [ 0  3  0  5  2  0  0  4  0]\n",
      " [ 0  0  0  1  2  0  0  0 14]]\n",
      "Testing Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.93      0.93      0.93        14\n",
      "   building        0.71      0.88      0.79        25\n",
      "        car        1.00      0.93      0.97        15\n",
      "   concrete        0.65      0.74      0.69        23\n",
      "      grass        0.83      0.86      0.85        29\n",
      "       pool        1.00      0.93      0.97        15\n",
      "     shadow        0.88      0.94      0.91        16\n",
      "       soil        0.80      0.29      0.42        14\n",
      "       tree        0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.82       168\n",
      "   macro avg       0.85      0.81      0.82       168\n",
      "weighted avg       0.83      0.82      0.81       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "from sklearn import metrics\n",
    "print(\"Testing Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_test, test_pred_svml))\n",
    "print(\"Testing Classification Report\")\n",
    "print(metrics.classification_report(y_test, test_pred_svml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix\n",
      "[[40  0  0  0  0  0  5  0  0]\n",
      " [ 2 87  0  7  0  0  1  0  0]\n",
      " [ 0  1 19  1  0  0  0  0  0]\n",
      " [ 0  9  0 83  1  0  0  0  0]\n",
      " [ 0  1  0  0 70  0  0  0 12]\n",
      " [ 0  1  0  0  1 12  0  0  0]\n",
      " [ 1  0  0  0  0  0 43  0  1]\n",
      " [ 0  3  0  4  2  0  0 11  0]\n",
      " [ 0  0  0  0  3  0  1  0 85]]\n",
      "Training Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.93      0.89      0.91        45\n",
      "   building        0.85      0.90      0.87        97\n",
      "        car        1.00      0.90      0.95        21\n",
      "   concrete        0.87      0.89      0.88        93\n",
      "      grass        0.91      0.84      0.88        83\n",
      "       pool        1.00      0.86      0.92        14\n",
      "     shadow        0.86      0.96      0.91        45\n",
      "       soil        1.00      0.55      0.71        20\n",
      "       tree        0.87      0.96      0.91        89\n",
      "\n",
      "    accuracy                           0.89       507\n",
      "   macro avg       0.92      0.86      0.88       507\n",
      "weighted avg       0.89      0.89      0.89       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#e)\n",
    "train_pred_svml = svm_linear_gs.predict(X_train_scaled)\n",
    "print(\"Training Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_train, train_pred_svml))\n",
    "print(\"Training Classification Report\")\n",
    "print(metrics.classification_report(y_train, train_pred_svml))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Are there signs of overfitting? Why or why not?\n",
    "\n",
    "Answer: There are slightly signs of overfitting. The training accuracy, precision, and recall scores are relatively high (almost in around 90%). However, the testing precision, recall accuracy and accuracy scores are relatively lower (in the low 80%), which is an indication that the model fits very well with the training data but not so well with the testing data (overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Support Vector Machine Classifier + Polynomial Kernel + Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 255 candidates, totalling 1275 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 744 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1268 out of 1275 | elapsed:   27.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1275 out of 1275 | elapsed:   27.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='poly', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': array([ 0.01,  0.2 ,  0.4 ,  0.6 ,  0.8 ,  1.  ,  1.2 ,  1.4 ,  1.6 ,\n",
       "        1.8 ,  2.  ,  2.2 ,  2.4 ,  2.6 ,  2.8 ,  3.  ,  3.2 ,  3.4 ,\n",
       "        3.6 ,  3.8 ,  4.  ,  4.2 ,  4.4 ,  4.6 ,  4.8 ,  5.  ,  5.2 ,\n",
       "        5.4 ,  5.6 ,  5.8 ,  6.  ,  6.2 ,  6.4 ,  6.6 ,  6.8 ,  7.  ,\n",
       "        7.2 ,  7.4 ,  7.6 ,  7.8 ,  8.  ,  8.2 ,  8.4 ,  8.6 ,  8.8 ,\n",
       "        9.  ,  9.2 ,  9.4 ,  9.6 ,  9.8 , 10.  ]),\n",
       "                         'degree': [2, 3, 4, 5, 6]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "from sklearn import svm\n",
    "svm_poly = svm.SVC(kernel='poly')\n",
    "parameters = {\n",
    "    'C': para,\n",
    "    'degree': [2, 3, 4, 5, 6]\n",
    "}\n",
    "svm_poly = GridSearchCV(svm_poly, parameters, cv=5, refit=True, n_jobs=-1, verbose=1)\n",
    "svm_poly.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Poly Grid Search best parameters {'C': 4.4, 'degree': 3}\n",
      "SVM Poly Grid Search best estimator SVC(C=4.4, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "print(\"SVM Poly Grid Search best parameters\",svm_poly.best_params_)\n",
    "print(\"SVM Poly Grid Search best estimator\",svm_poly.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c)\n",
    "svm_poly_gs = svm_poly.best_estimator_\n",
    "test_pred_svmp = svm_poly_gs.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Confusion Matrix\n",
      "[[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 22  0  2  1  0  0  0  0]\n",
      " [ 0  2 11  0  0  1  0  1  0]\n",
      " [ 0  5  0 17  1  0  0  0  0]\n",
      " [ 0  0  0  0 26  0  0  1  2]\n",
      " [ 0  0  0  0  0 14  1  0  0]\n",
      " [ 1  0  0  0  0  0 14  0  1]\n",
      " [ 0  3  0  5  6  0  0  0  0]\n",
      " [ 0  0  0  1  3  0  0  0 13]]\n",
      "Testing Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.93      0.93      0.93        14\n",
      "   building        0.69      0.88      0.77        25\n",
      "        car        1.00      0.73      0.85        15\n",
      "   concrete        0.68      0.74      0.71        23\n",
      "      grass        0.70      0.90      0.79        29\n",
      "       pool        0.93      0.93      0.93        15\n",
      "     shadow        0.88      0.88      0.88        16\n",
      "       soil        0.00      0.00      0.00        14\n",
      "       tree        0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.77       168\n",
      "   macro avg       0.74      0.75      0.74       168\n",
      "weighted avg       0.73      0.77      0.75       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "from sklearn import metrics\n",
    "print(\"Testing Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_test, test_pred_svmp))\n",
    "print(\"Testing Classification Report\")\n",
    "print(metrics.classification_report(y_test, test_pred_svmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix\n",
      "[[44  0  0  0  1  0  0  0  0]\n",
      " [ 0 95  0  1  1  0  0  0  0]\n",
      " [ 0  0 20  0  1  0  0  0  0]\n",
      " [ 0  1  0 91  1  0  0  0  0]\n",
      " [ 0  1  0  0 81  0  0  0  1]\n",
      " [ 0  0  0  0  1 13  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0]\n",
      " [ 0  0  0  0  9  0  0 11  0]\n",
      " [ 0  0  0  0  3  0  0  0 86]]\n",
      "Training Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        1.00      0.98      0.99        45\n",
      "   building        0.98      0.98      0.98        97\n",
      "        car        1.00      0.95      0.98        21\n",
      "   concrete        0.99      0.98      0.98        93\n",
      "      grass        0.83      0.98      0.90        83\n",
      "       pool        1.00      0.93      0.96        14\n",
      "     shadow        1.00      1.00      1.00        45\n",
      "       soil        1.00      0.55      0.71        20\n",
      "       tree        0.99      0.97      0.98        89\n",
      "\n",
      "    accuracy                           0.96       507\n",
      "   macro avg       0.98      0.92      0.94       507\n",
      "weighted avg       0.96      0.96      0.96       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#e)\n",
    "train_pred_svmp = svm_poly_gs.predict(X_train_scaled)\n",
    "print(\"Training Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_train, train_pred_svmp))\n",
    "print(\"Training Classification Report\")\n",
    "print(metrics.classification_report(y_train, train_pred_svmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Are there signs of overfitting? Why or why not?\n",
    "\n",
    "Answer: There are slightly signs of overfitting. The training accuracy, precision, and recall scores are relatively high (almost all around high 90s%). However, the testing precision, recall accuracy and accuracy scores are significantly lower (except for class car), which is an indication that the model fits very well with the training data but not so well with the testing data (overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Support Vector Machine Classifier + RBF Kernel + Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 255 candidates, totalling 1275 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1268 out of 1275 | elapsed:   48.7s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1275 out of 1275 | elapsed:   49.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': array([ 0.01,  0.2 ,  0.4 ,  0.6 ,  0.8 ,  1.  ,  1.2 ,  1.4 ,  1.6 ,\n",
       "        1.8 ,  2.  ,  2.2 ,  2.4 ,  2.6 ,  2.8 ,  3.  ,  3.2 ,  3.4 ,\n",
       "        3.6 ,  3.8 ,  4.  ,  4.2 ,  4.4 ,  4.6 ,  4.8 ,  5.  ,  5.2 ,\n",
       "        5.4 ,  5.6 ,  5.8 ,  6.  ,  6.2 ,  6.4 ,  6.6 ,  6.8 ,  7.  ,\n",
       "        7.2 ,  7.4 ,  7.6 ,  7.8 ,  8.  ,  8.2 ,  8.4 ,  8.6 ,  8.8 ,\n",
       "        9.  ,  9.2 ,  9.4 ,  9.6 ,  9.8 , 10.  ]),\n",
       "                         'gamma': [0.01, 0.1, 1, 10, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "from sklearn import svm\n",
    "svm_rbf = svm.SVC(kernel=\"rbf\")\n",
    "parameters = {\n",
    "    'C': para,\n",
    "    'gamma': [0.01,  0.1, 1, 10, 100]\n",
    "}\n",
    "svm_rbf = GridSearchCV(svm_rbf, parameters, cv=5, refit=True, n_jobs=-1, verbose=1)\n",
    "svm_rbf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM RBF Grid Search best parameters {'C': 2.8000000000000003, 'gamma': 0.01}\n",
      "SVM RBF Grid Search best estimator SVC(C=2.8000000000000003, break_ties=False, cache_size=200, class_weight=None,\n",
      "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.01,\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "print(\"SVM RBF Grid Search best parameters\",svm_rbf.best_params_)\n",
    "print(\"SVM RBF Grid Search best estimator\",svm_rbf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c)\n",
    "svm_rbf_gs = svm_rbf.best_estimator_\n",
    "test_pred_svmrbf = svm_rbf_gs.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Confusion Matrix\n",
      "[[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 21  0  3  1  0  0  0  0]\n",
      " [ 0  1 14  0  0  0  0  0  0]\n",
      " [ 0  4  0 19  0  0  0  0  0]\n",
      " [ 0  1  0  0 26  0  0  0  2]\n",
      " [ 0  0  0  0  0 14  1  0  0]\n",
      " [ 1  0  0  0  0  0 15  0  0]\n",
      " [ 0  2  0  4  3  0  0  5  0]\n",
      " [ 0  0  0  1  1  0  0  0 15]]\n",
      "Testing Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.93      0.93      0.93        14\n",
      "   building        0.72      0.84      0.78        25\n",
      "        car        1.00      0.93      0.97        15\n",
      "   concrete        0.70      0.83      0.76        23\n",
      "      grass        0.84      0.90      0.87        29\n",
      "       pool        1.00      0.93      0.97        15\n",
      "     shadow        0.88      0.94      0.91        16\n",
      "       soil        1.00      0.36      0.53        14\n",
      "       tree        0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.85       168\n",
      "   macro avg       0.88      0.84      0.84       168\n",
      "weighted avg       0.86      0.85      0.84       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "from sklearn import metrics\n",
    "print(\"Testing Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_test, test_pred_svmrbf))\n",
    "print(\"Testing Classification Report\")\n",
    "print(metrics.classification_report(y_test, test_pred_svmrbf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix\n",
      "[[45  0  0  0  0  0  0  0  0]\n",
      " [ 0 96  0  1  0  0  0  0  0]\n",
      " [ 0  0 21  0  0  0  0  0  0]\n",
      " [ 0  1  0 92  0  0  0  0  0]\n",
      " [ 0  1  0  0 81  0  0  0  1]\n",
      " [ 0  0  0  0  0 14  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0]\n",
      " [ 0  1  0  0  0  0  0 19  0]\n",
      " [ 0  0  0  0  1  0  0  0 88]]\n",
      "Training Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        1.00      1.00      1.00        45\n",
      "   building        0.97      0.99      0.98        97\n",
      "        car        1.00      1.00      1.00        21\n",
      "   concrete        0.99      0.99      0.99        93\n",
      "      grass        0.99      0.98      0.98        83\n",
      "       pool        1.00      1.00      1.00        14\n",
      "     shadow        1.00      1.00      1.00        45\n",
      "       soil        1.00      0.95      0.97        20\n",
      "       tree        0.99      0.99      0.99        89\n",
      "\n",
      "    accuracy                           0.99       507\n",
      "   macro avg       0.99      0.99      0.99       507\n",
      "weighted avg       0.99      0.99      0.99       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#e)\n",
    "train_pred_svmrbf = svm_rbf_gs.predict(X_train_scaled)\n",
    "print(\"Training Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_train, train_pred_svmrbf))\n",
    "print(\"Training Classification Report\")\n",
    "print(metrics.classification_report(y_train, train_pred_svmrbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Are there signs of overfitting? Why or why not?\n",
    "\n",
    "Answer: There are signs of overfitting. The training accuracy, precision, and recall scores are extremely high (all in high 90% or perfect 100%), which is an sign of overfitting. In addition, the testing precision, recall accuracy and accuracy scores are relatively lower (except for class car, class pool and class soil), which is an indication that the model fits very well with the training data but not so well with the testing data (overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Conceptual Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) From the models run in steps 2-6, which performs the best based on the Classification Report? Support your reasoning with evidence around your test data. \n",
    "\n",
    "Answer: From the models run in steps 2-6, in terms of testing score, Random Forest Base Model (step 2) Support Vector Machine Classifier with RBF Kernel (step 6) and Linear Kernel (step 4) all have a relatively higher testing accruacy score (85%, 83% and 82%). \n",
    "\n",
    "However, Random Forest Classifier (step 2), Linear SVM Classifier - Base Model (step 3), Support Vector Machine Classifier with Polynomial Kernel (step 5) and RBF Kernel (step 6) all have very high training accuracy rate (all in high 90s% or perfect 100%), which are signs of overfitting. Plus, there significant difference between training and testing scores, which indicates that there is sign of overfitting. Support Vector Machine with Linear Kernel performs slightly better in terms of overfitting. It has a relatively lower training score and the difference between training and testing is the smallest among all the models (89% training and 82% testing). Therefore, Support Vector Machine Classifier with Linear Kernel with Grid Search performs the best based on the classification report. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Compare models run for steps 4-6 where different kernels were used. What is the benefit of using a polynomial or rbf kernel over a linear kernel? What could be a downside of using a polynomial or rbf kernel? \n",
    "\n",
    "Answer: Based on training and testing accruacy and overfit assessment, the Linear Kernel SVM performs the best in testing accuracy and is the only model that does not have obvious sign of overfitting. The best performing kernel signifies the true separator of the dataset. In this case, we can say that a linear function is the best approximation of the true separator of the dataset as compare to polynomial separators and radial basis function, which is an sign that our data can be separated by a linear transformation. The benefit of using polynomial or rbf kernel over a linear kernel is when the true separator line more complex than a linear line, and in this case, using a linear kernel might underfit the data. On contrast, the downside of using a polynomial or rbf kernel is when the true separator is linear but we are using polynomial or rbf kernel to fit our data. In this case, our model will be overfitted, which is the case for this homework in step 5-6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Explain the 'C' parameter used in steps 4-6. What does a small C mean versus a large C in sklearn? Why is it important to use the 'C' parameter when fitting a model? \n",
    "\n",
    "Answer: The \"C\" parameter used in steps 4-6 to determine the total error tolerance. The error is calculated whenever a datapoint is misclassified, and the total error (number of misclassification) cannot exceed the value \"C\". This parameter is important when fitting a model because a high value of \"C\" means the model has a wider margin and can tolerate higher error. Therefore, if the \"C\" value is too high, the model might be underfitting as it gives too much tolerance to misclassification. On contrast, when the value of \"C\" is low, the model has narrow margin and gives low tolerance to misclassification. Therefore, if the \"C\" value is too low, the model might be overfitting.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Scaling our input data does not matter much for Random Forest, but it is a critical step for Support Vector Machines. Explain why this is such a critical step. Also, provide an example of a feature from this data set that could cause issues with our SVMs if not scaled.\n",
    "\n",
    "Answer: In SVMs, we are trying to find the hyperplane for maximize the margin (best separate) between the different classes. If one feature has very large values, one dimension in this space will be very long and dominates the other dimensions (other features) when maximizing the margin distnace and determining the hyperplane. The hyperplane will be distored and focus only on separating the classes based on the dominate feature. Therefore, it is critical to scale all the features before performing a SVM so that all the features has the same influence on determining the hyperplane separator. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Describe conceptually what the purpose of a kernel is for Support Vector Machines.\n",
    "\n",
    "Answer: The kernel trick provides a solution to transform from low dimension to higher dimensional vectors in the transformed feature space, which allow us to separate data that is non-separable in low dimension. For instance, when the original data is in a line (1 dimension) and is non-separable by a dot (e.g. each pair of class 1 data point and class 2 data point follow each other sequentially), we can transform this data into a plane (2 dimensions) and use a line to separate the data.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
